{
  "issue_id": "_claude_issue_024",
  "title": "PATTERN: 28+ nodes missing 90-99% of properties - spread operators from './descriptions' imports not resolved",
  "severity": "critical",
  "status": "resolved",
  "priority": 1,
  "metadata": {
    "created_at": "2025-11-07T00:30:00Z",
    "created_by": "claude_code",
    "affected_nodes": "28+ nodes including: Elasticsearch, Stripe, Copper, Git, Grafana, Odoo, QuickBooks, ActionNetwork, Freshservice, Gong, GoToWebinar, HaloPSA, Kitemaker, Marketstack, Misp, MistralAI, MonicaCrm, Perplexity, Raindrop, Simulate, CrowdDev, FreshworksCrm + 6 more",
    "validation_session": "comprehensive_cross_reference_2025-11-07",
    "related_issues": "_claude_issue_021 (specific Elasticsearch case)"
  },
  "description": {
    "problem": "Systematic failure affecting 28+ nodes that use the pattern: import descriptions from './descriptions' directory, then spread them into properties array. Only the resource selector is extracted (1-4 properties), while 50-90+ properties from spread-imported description files are completely missing.",
    "impact": "CATASTROPHIC - Affects 6% of all nodes (28/450). Estimated 2000+ properties missing across all affected nodes. These nodes are essentially undocumented, making AI training impossible for these integrations. Each node loses 90-99% of its configuration options.",
    "root_cause": "Extractor's spread resolution (n8n_node_extractor.py lines 641-687) only handles spreads within the same file. It does NOT follow imports to resolve spreads from external files.\n\nCommon pattern in affected nodes:\n```typescript\n// Main .node.ts file\nimport {\n  resourceOperations,\n  resourceFields,\n  // ... more imports\n} from './descriptions';\n\nexport class NodeName implements INodeType {\n  description: INodeTypeDescription = {\n    properties: [\n      { displayName: 'Resource', name: 'resource', ... },\n      ...resourceOperations,  // \u274c NOT RESOLVED\n      ...resourceFields,       // \u274c NOT RESOLVED\n      // ... more spreads\n    ]\n  }\n}\n```\n\nThe extractor extracts only the inline resource selector, ignoring all spread operators that reference imported arrays.",
    "evidence": [
      "PATTERN IDENTIFICATION:",
      "  $ grep -l \"from './descriptions'\" n8n/packages/nodes-base/nodes/*/*.node.ts | wc -l",
      "  Output: 28 nodes",
      "",
      "AFFECTED NODES VERIFICATION (sample):",
      "",
      "1. Elasticsearch",
      "   - Extracted: 1 property",
      "   - Source descriptions: documentOperations (1) + documentFields (70) + indexOperations (1) + indexFields (22) = 94 properties",
      "   - Loss: 93 properties (99% missing)",
      "",
      "2. Stripe",
      "   - Extracted: 1 property",
      "   - Source descriptions: 7 description files (Balance, Charge, Coupon, Customer, CustomerCard, Source, Token)",
      "   - Estimated: 100+ properties",
      "   - Loss: 99+ properties (99% missing)",
      "",
      "3. Copper",
      "   - Extracted: 1 property",
      "   - Has descriptions directory",
      "   - Loss: ~95% estimated",
      "",
      "4. Git",
      "   - Extracted: 4 properties",
      "   - Has descriptions directory",
      "   - Loss: ~90% estimated",
      "",
      "5. Grafana",
      "   - Extracted: 1 property",
      "   - Has descriptions directory",
      "   - Loss: ~95% estimated",
      "",
      "6. Odoo",
      "   - Extracted: 1 property",
      "   - Has descriptions directory",
      "   - Loss: ~95% estimated",
      "",
      "7. QuickBooks",
      "   - Extracted: 1 property",
      "   - Has descriptions directory  ",
      "   - Loss: ~95% estimated",
      "",
      "8. ActionNetwork",
      "   - Extracted: 1 property",
      "   - Has descriptions directory",
      "   - Loss: ~95% estimated",
      "",
      "9. Freshservice",
      "   - Extracted: 1 property",
      "   - Has descriptions directory",
      "   - Loss: ~95% estimated",
      "",
      "10. Gong",
      "   - Extracted: 2 properties",
      "   - Has descriptions directory",
      "   - Loss: ~90% estimated",
      "",
      "COMPLETE LIST OF 28 AFFECTED NODES:",
      "ActionNetwork, Copper, CrowdDev, Elasticsearch, Freshservice, FreshworksCrm,",
      "Git, Gong, GoToWebinar, Grafana, HaloPSA, Kitemaker, Marketstack, Misp,",
      "MistralAI, MonicaCrm, Odoo, Perplexity, QuickBooks, Raindrop, Simulate,",
      "Stripe, + 6 more to be identified",
      "",
      "TOTAL IMPACT ESTIMATE:",
      "  - 28 nodes \u00d7 70 properties average = 1,960 properties missing",
      "  - Actual extraction: 28 nodes \u00d7 1.5 properties average = 42 properties",
      "  - Missing: ~1,918 properties (98% loss across pattern)",
      "",
      "VERIFICATION COMMANDS:",
      "  $ jq '.properties | length' extracted_docs/elasticsearch_data.json",
      "  Output: 1",
      "",
      "  $ jq '.properties | length' extracted_docs/stripe_data.json",
      "  Output: 1",
      "",
      "  $ jq '.properties | length' extracted_docs/copper_data.json",
      "  Output: 1"
    ],
    "fix_approach": "Implement import-aware spread resolution in TypeScriptParser:\n\n1. Enhance _resolve_spreads() method (lines 641-687):\n   - Add imports parameter (from parse_imports())\n   - When encountering ...identifier:\n     a) Check if identifier exists in current file scope (current behavior)\n     b) If not found, check if identifier in imports dictionary\n     c) If imported, resolve the import path and read source file\n     d) Extract the exported array using extract_exported_array()\n     e) Recursively resolve any nested spreads\n     f) Return resolved properties\n\n2. Update call sites to pass imports:\n   - NodeExtractor.extract_info() around line 950\n   - Pass self.imports to _resolve_spreads()\n\n3. Handle './descriptions' index.ts pattern:\n   - When import path is './descriptions', resolve to './descriptions/index.ts'\n   - Parse index.ts to find re-exports\n   - Follow re-export chain to actual description files\n\n4. Implement recursive import resolution:\n   - Description files may import from other files\n   - Need recursive resolution to handle nested imports\n   - Track visited files to avoid circular imports\n\n5. Cache imported arrays:\n   - Avoid re-parsing same description files multiple times\n   - Store parsed results in dictionary keyed by file path\n\n6. Testing strategy:\n   - Test with all 28 affected nodes\n   - Verify property counts increase from 1-4 to 50-100+\n   - Spot-check 5 nodes for correct property extraction\n   - Run validation to ensure no regressions\n\n7. Success criteria:\n   - Elasticsearch: 1 \u2192 94 properties\n   - Stripe: 1 \u2192 100+ properties\n   - All 28 nodes show 50+ properties\n   - Zero properties count: 1 (only NoOp)\n\nImplementation priority: CRITICAL - This single fix will improve extraction quality by 10-15% overall (28/450 nodes = 6% of nodes, but high-value complex nodes)."
  },
  "ownership": {
    "assigned_to": "claude_code",
    "locked_by": null,
    "lock_acquired_at": null,
    "lock_expires_at": null,
    "claimed_at": "2025-11-07T19:43:29.033262Z"
  },
  "resolved_by": "claude_code",
  "resolved_at": "2025-11-07T21:34:14.982249Z"
}